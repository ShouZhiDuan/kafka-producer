#端口
server.port=80

#MySQL数据库配置
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://192.168.10.28:3306/medusa_license_db?useSSL=false&useUnicode=true&characterEncoding=utf8
spring.datasource.username=root
spring.datasource.password=Wentiliangkaihua@2021
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.jpa.database-platform=org.hibernate.dialect.MySQL5InnoDBDialect
spring.jpa.show-sql=true
spring.jpa.hibernate.ddl-auto=update
#spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl


######################################
################生产端################
######################################
spring.kafka.bootstrap-servers=192.168.10.33:9092,192.168.10.34:9092
#发送异常重试次数
spring.kafka.producer.retries=3
#发送消息堆积数据大小 单位：KB
spring.kafka.producer.batch-size=4096
#发送端内存缓冲区大小 单位：KB
spring.kafka.producer.buffer-memory=40960
#发送端序列化方式
spring.kafka.producer.key-erializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer



######################################
################消费端################
######################################
spring.kafka.consumer.group-id=my_consumer_1
#earliest表示当前消费组若有提交offset则消费offset之后的所有新消息，没有offset历史记录则从头开始消费所有的消息。
#latest表示当前消费组不管有没有历史offset,都将只消费从消费者程序起动后的新消息。注意这里如果一个全新消费组开始就指定latest那么前面所有的而历史数据offset都将被提交，后续你再换成earliest也还是不会去消费前面的历史消息。
spring.kafka.consumer.auto-offset-reset=earliest
#消费端单次批量拉取消息的最大数量
spring.kafka.consumer.max-poll-records=10
#自动提交的间隔时间，默认值是 5000，单位是毫秒
spring.kafka.consumer.auto-commit-interval=3000
#是否开启自动提交功能，默认开启的
spring.kafka.consumer.enable-auto-commit=false
#消息序列化
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

